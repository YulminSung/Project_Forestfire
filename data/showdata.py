# -*- coding: utf-8 -*-
import pandas as pd
import streamlit as st
from google.cloud import bigquery
from streamlit_pandas_profiling import st_profile_report

from data.query import run_query
from utils import credentials

# ë¹…ì¿¼ë¦¬ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
client = bigquery.Client(credentials=credentials, project=credentials.project_id)

def run_show_data():
    tab1, tab2 = st.tabs(["âœ…Data List", "âœ…Show Data"])
    with tab1:
        # ë¹…ì¿¼ë¦¬ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
        client = bigquery.Client(credentials=credentials, project=credentials.project_id)
        # ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ
        st.header("Data Set List")
        # ë°ì´í„°ì…‹ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        datasets = list(client.list_datasets())
        # ë°ì´í„°ì…‹ ëª©ë¡ì„ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        dataset_list = []
        # ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ë°ì´í„°ì…‹ IDë¥¼ ê°€ì ¸ì™€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        for dataset in datasets:
            dataset_list.append(dataset.dataset_id)
        df_datasets = pd.DataFrame({"Data Set List": dataset_list})
        st.dataframe(df_datasets)

        # íŠ¹ì • ë°ì´í„°ì…‹ì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        st.subheader("DataTable List")
        dataset_list = st.selectbox("Select Date Set",
                                    ('Analysis_Data', 'PreProcessing_Data', 'Raw_Data'))  # ì›í•˜ëŠ” ë°ì´í„°ì…‹ IDë¡œ ë³€ê²½
        if dataset_list:
            dataset_id = dataset_list
            tables = list(client.list_tables(dataset_id))
            datatable_list = []
            for table in tables:
                datatable_list.append(table.table_id)
            df_tables = pd.DataFrame({"Table List": datatable_list})
            st.dataframe(df_tables)
    with tab2:
        """
           Display the dataframe, data types, and describe statistics in a Streamlit-style format.
    
           :param dataframe: The input dataframe.
           :return: None
        """
        st.markdown("**Data Set List**")
        # ë°ì´í„°ì…‹ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        datasets = list(client.list_datasets())
        # ë°ì´í„°ì…‹ ëª©ë¡ì„ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        dataset_list = []
        # ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ë°ì´í„°ì…‹ IDë¥¼ ê°€ì ¸ì™€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        for dataset in datasets:
            dataset_list.append(dataset.dataset_id)

        dataset_list = st.selectbox("DateSet", ('Analysis_Data', 'PreProcessing_Data', 'Raw_Data'),
                                    label_visibility='collapsed')  # ì›í•˜ëŠ” ë°ì´í„°ì…‹ IDë¡œ ë³€ê²½
        # íŠ¹ì • ë°ì´í„°ì…‹ì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        st.markdown("**Data Table List**")
        dataset_id = dataset_list
        tables = list(client.list_tables(dataset_id))
        datatable_list = []
        for table in tables:
            datatable_list.append(table.table_id)
        df_tables = pd.DataFrame({"Table List": datatable_list})
        tablenames = st.selectbox("DataTable", df_tables, label_visibility='collapsed')

        tab1, tab2 = st.tabs(["ğŸ—ƒï¸Data Preview", "âœ…View Columns"])
        with tab1:
            if dataset_list =='Analysis_Data':
                st.markdown("#### ğŸ—ƒï¸ Analysis Data Set : ë¶„ì„ì„ ìœ„í•œ ì „ì²˜ë¦¬ ë°ì´í„°")
                st.markdown("- ê°•ì›ë„ ê° ì§€ì—­ì˜ :red[**ì‚°ë¶ˆë°œìƒì—¬ë¶€**] ë° **ê¸°ìƒ ë°ì´í„°** ë¥¼ í¬í•¨ \n"
                            "- ê¸°ìƒ ë°ì´í„°ì—ëŠ” **ê¸°ì˜¨, ìŠµë„, ë°”ëŒ, ê°•ìˆ˜** ì— ëŒ€í•œ ë‚´ìš© \n"
                            "- ë˜í•œ ê° ì§€ì—­ì€ 9ê°œ êµ¬ì—­ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì ¸ ìˆìŒ \n"
                            "- 9ê°œ êµ¬ì—­ \n"
                            "   + ê°•ì› ì¤‘ë¶€ í•´ì•ˆ : ê°•ë¦‰ì‹œ \n"
                            "   + ê°•ì› ì¤‘ë¶€ ë‚´ë¥™ : ì¶˜ì²œì‹œ, í™ì²œêµ°(~ë‚´ë©´) \n"
                            "   + ê°•ì› ì¤‘ë¶€ ì‚°ì§€ : í™ì²œêµ°(ë‚´ë©´), í‰ì°½êµ°(ëŒ€ê´€ë ¹ë©´, ì§„ë¶€ë©´) \n"
                            "   + ê°•ì› ë¶ë¶€ í•´ì•ˆ : ê³ ì„±êµ°, ì†ì´ˆì‹œ, ì–‘ì–‘êµ° \n"
                            "   + ê°•ì› ë¶ë¶€ ë‚´ë¥™ : ì² ì›êµ°, í™”ì²œêµ° \n"
                            "   + ê°•ì› ë¶ë¶€ ì‚°ì§€ : ì–‘êµ¬êµ°, ì¸ì œêµ° \n"
                            "   + ê°•ì› ë‚¨ë¶€ í•´ì•ˆ : ë™í•´ì‹œ, ì‚¼ì²™ì‹œ, íƒœë°±ì‹œ \n"
                            "   + ê°•ì› ë‚¨ë¶€ ë‚´ë¥™ : ì›ì£¼ì‹œ, íš¡ì„±êµ° \n"
                            "   + ê°•ì› ë‚¨ë¶€ ì‚°ì§€ : ì—´ì›”êµ°, ì •ì„ êµ°, í‰ì°½êµ°(~ëŒ€ê´€ë ¹ë©´, ~ì§„ë¶€ë©´) \n"
                            "")
            elif dataset_list =='PreProcessing_Data':
                st.markdown("#### ğŸ—ƒï¸ PreProcessing_Data Set : ê¸°ì´ˆ ì „ì²˜ë¦¬ ë°ì´í„°")
                st.markdown("- **forestfire_occurs** : ì‚°ë¶ˆ ë°œìƒ ì´ë ¥ \n"
                            "- **weather_days** : ì¼ê°„ ê¸°ìƒ ìë£Œ \n"
                            "- **weather_stations** : ê¸°ìƒ ê´€ì¸¡ ì§€ì  ìë£Œ \n")
            elif dataset_list =='Raw_Data':
                st.markdown("#### ğŸ—ƒï¸ Raw_Data Set : Open APIë¥¼ í†µí•´ ìˆ˜ì§‘í•œ ê³µê³µ ë°ì´í„°")
                st.markdown("- **ë°ì´í„° ì¶œì²˜** : ì‚°ë¦¼ì²­, ê¸°ìƒì²­, êµ­í† êµí†µë¶€, í–‰ì •ì•ˆì „ë¶€ \n")

            col1, col2 = st.columns([3, 2])
            with col1:
                st.subheader("ğŸ“£ Data")
                if tablenames:
                    table_id = tablenames
                    query = f"""
                        SELECT *
                        FROM `forestfire-389107.{dataset_id}.{table_id}`
                        """
                    # ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                    combined_df = client.query(query).to_dataframe()
                    # ë°ì´í„°í”„ë ˆì„ ì¶œë ¥
                    st.dataframe(combined_df)
                    # IMPORTANT: Cache the conversion to prevent computation on every rerun
                    csv = combined_df.to_csv().encode('cp949')
                    st.download_button(
                        label="Download data as CSV",
                        data=csv,
                        file_name=f'{tablenames}.csv',
                        mime='text/csv')
                with st.expander("Report"):
                    pr = combined_df.profile_report()
                    st_profile_report(pr)

            with col2:
                st.subheader("ğŸ“£ Describe")

                st.dataframe(combined_df.describe(), height=350, width=650)
                st.write("*Appendix ë©”ë‰´ì˜ Codebook ì°¸ê³ ")
        with tab2:
            if tablenames:
                dataset_id = dataset_list
                query = f"""
                    SELECT STRING_AGG(column_name)
                    FROM `forestfire-389107.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
                    group by table_name
                    """
                df = client.query(query).to_dataframe()
                all_cols = df.values[0][0].split(",")
                st.markdown("**Select Columns**")
                columns = st.multiselect("ì»¬ëŸ¼ëª… ì„ íƒ", all_cols, default=all_cols, label_visibility='collapsed')
                temp_Strings = ", ".join(columns)
                run_query(temp_Strings, dataset_id, tablenames)
            else :
                st.warning("error")

if __name__ == "__main__":
    run_show_data()